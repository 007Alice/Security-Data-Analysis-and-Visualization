{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import requests\n",
    "import re\n",
    "import tldextract\n",
    "from bs4 import BeautifulSoup\n",
    "init_url='http://l-team.org/about-us.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#当友链是单独页面时，从首页提取友链页面链接，再提取友链\n",
    "#存在网页解码识别不了“友情链接”问题https://www.sqlsec.com\n",
    "def from_index_search_links(url):\n",
    "    try:\n",
    "        a_url=''\n",
    "        s = requests.session()\n",
    "        s.keep_alive = False\n",
    "        s.adapters.DEFAULT_RETRIES = 10\n",
    "        result=s.get(url,timeout=10)\n",
    "        bsObj=BeautifulSoup(result.text,'html.parser')\n",
    "        a_links=bsObj.find_all('a')\n",
    "        for a_link in a_links:\n",
    "            #print(a_link)\n",
    "            #if '友链' in a_link.text or '友情链接' in a_link.text or 'FriendLink' in a_link.text or 'Friendlink' in a_link.text or 'friends' in a_link.text or 'links' in a_link.text or 'Friends' in a_link.text or 'Links' in a_link.text:\n",
    "            if [True for str in (\"友链\",\"友情链接\",\"FriendLink\",\"Friendlink\",\"friends\",\"FRIENDS\",'links','Links','Link')if str in a_link.text]:\n",
    "                if 'http' not in a_link.get('href'):\n",
    "                    a_url=url.rstrip('/')+a_link.get('href')\n",
    "                else:\n",
    "                    a_url=a_link.get('href')\n",
    "            \n",
    "        return a_url\n",
    "    except Exception as err:\n",
    "        #print(str(err))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_link_search_friend(link):\n",
    "    friend_link_url={}\n",
    "    try:    \n",
    "        s = requests.session()\n",
    "        s.keep_alive = False\n",
    "        s.adapters.DEFAULT_RETRIES = 10\n",
    "        result=s.get(link,timeout=10)\n",
    "        bsObj=BeautifulSoup(result.text,'html.parser')\n",
    "        a_urls = bsObj.find_all('a')\n",
    "        for a_url in a_urls:\n",
    "            if re.search('http(.+?)(com|net|blog|pw|cc|xyz|club|org|cn|io|info|me|im|link)(\\/)?$',a_url.get('href')) != None and a_url.get('href') not in link:\n",
    "                #print(a_url.get('href'),a_url.text)\n",
    "                if a_url.get('href')!='http://www.52bug.cn':\n",
    "                    friend_link_url[a_url.text.strip('\\n')]=(a_url.get('href').strip('/'))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "        #print(str(e))\n",
    "    #print(len(friend_link_url.keys()))\n",
    "    return friend_link_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#增加主页关键字\"链接\" or \"Links\" https://www.virzz.com\n",
    "#http://iamstudy.cnblogs.com/\n",
    "#需要增加关键字Bookmarks（https://www.melodia.pw/的section标签中）,Friendship website（http://poetichacker.com/的div标签中）\n",
    "def search_link(key,url):\n",
    "    result=[]\n",
    "    friend_link_url={}\n",
    "    try:\n",
    "        html_result=requests.get(url)\n",
    "        status=False\n",
    "        #print(url)\n",
    "        if [True for str in (\"友链\",\"友情链接\",\"FriendLink\",\"Friendlink\",\"friends\",\"FRIENDS\",'Friends')if str in html_result.text]:\n",
    "            bsObj = BeautifulSoup(html_result.text, 'html.parser')\n",
    "            searchs=['section','aside','div']\n",
    "            for search in searchs:\n",
    "                sections = bsObj.find_all(search)\n",
    "                for section in sections:\n",
    "                    if [True for str in (\"友链\",\"友情链接\",\"FriendLink\",\"Friendlink\",\"friends\",'FRIENDS','Friends')if str in section.text]:\n",
    "                        #print(\"在{}发现主页{}的友情链接\".format(search,url))\n",
    "                        a_urls = section.find_all('a')\n",
    "                        \n",
    "                        friend_link_url={}\n",
    "                        for a_url in a_urls:\n",
    "                            #print(a_url.get('href'))\n",
    "                            if a_url.get('href')!=None:\n",
    "                                ext=tldextract.extract(a_url.get('href'))\n",
    "                                main_domain=ext.domain+'.'+ext.suffix\n",
    "                                if re.search('(http)?(.+?)(com|net|blog|pw|cc|xyz|club|org|cn|io|info|me|im|win|link)(\\/)?$',a_url.get('href')) != None and main_domain not in url:\n",
    "                                    #print(a_url.text,(a_url.get('href').strip('/')))\n",
    "                                    if a_url.get('href')!='http://www.52bug.cn':\n",
    "                                        friend_link_url[a_url.text]=(a_url.get('href').strip('/'))\n",
    "                                        status=True\n",
    "                            \n",
    "                        \n",
    "                        if friend_link_url:\n",
    "                            result.append(friend_link_url)\n",
    "                if len(result)>1:\n",
    "                    #取交集       \n",
    "                    #print(\"友链出现在多个同样标签中，请手工验证{}\".format(url))\n",
    "                    #print(result)\n",
    "                    #no_link.pop(key)\n",
    "                    return result[-1],key\n",
    "                    \n",
    "                if status==True:\n",
    "                    break\n",
    "            if status==False:\n",
    "                #print('未在已有标签中发现{}友链，可能存在于其他标签中,请手工验证'.format(url))\n",
    "                pass\n",
    "            #no_link.pop(key)\n",
    "        else:\n",
    "            #print('未发现友链关键字%s' %url)\n",
    "            pass\n",
    "       \n",
    "    except Exception as e:\n",
    "        #print(\"{}{}\".format(url,e))\n",
    "        pass\n",
    "    \n",
    "    return friend_link_url,key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_security_blog(url_dict):\n",
    "    print(\"Start search security blogs\")\n",
    "    security_dict={}\n",
    "    no_security_dict={}\n",
    "    s = requests.session()\n",
    "    s.keep_alive = False\n",
    "    s.adapters.DEFAULT_RETRIES = 15\n",
    "    for key in url_dict.keys():\n",
    "        try:\n",
    "            if not url_dict[key].startswith(\"http\"):\n",
    "                url_dict[key]=\"http://\"+url_dict[key]\n",
    "            #print(key,url_dict[key],s.get(url_dict[key],timeout=10))\n",
    "            html=s.get(url_dict[key],timeout=10)\n",
    "            html.encoding=\"utf-8\"\n",
    "            if html.status_code==200:\n",
    "                if [True for str in (\"二进制安全\",\"安全攻防\",\"安全数据\",\"安全运营\",\"XSS\",\"信息安全协会\",\"代码审计\",\"网络安全\",\"security\",\"Penetration\",'渗透','CTF','CSRF','SQL注入','RCE','CVE','漏洞分析','安全研究')if str in html.text]:\n",
    "                    security_dict[key]=url_dict[key]\n",
    "                else:\n",
    "                    no_security_dict[key]=url_dict[key]\n",
    "                    \n",
    "            else:\n",
    "                #print(\"网页暂时打不开\")\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            #print(\"{}{}\".format(e,url_dict[key]))\n",
    "            pass\n",
    "            no_security_dict[key]=url_dict[key]  \n",
    "    return security_dict,no_security_dict\n",
    "#search_link('xjj','http://www.yqxiaojunjie.com/')\n",
    "#test\n",
    "#print(from_link_search_friend(from_index_search_links('http://balis0ng.com')))\n",
    "#print(from_index_search_links('http://le4f.net'))\n",
    "#print(from_index_search_links('http://leavesongs.com'))\n",
    "#print(from_index_search_links('http://www.venenof.com'))\n",
    "#search_link('f','http://wooyaa.me/')\n",
    "#find_security_blog({'1': 'https://www.youngxj.cn/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now {'L-team': {'http://l-team.org/about-us.html': {'tools': 'http://tool.leavesongs.com', 'Da2din9o': 'http://dazdingo.net', 'Zing': 'http://z1ng.net', 'DM_': 'http://x0day.me', 'Phiti0n': 'http://leavesongs.com', 'Le4F': 'http://le4f.net', 'Kuuki': 'http://blog.esu.im', 'Bigtang': 'http://bigtang.org', 'Chu': 'http://sh3ll.me', 'Cyrils': 'http://www.cyrils.org', 'F0r': 'http://www.f0r.info', 'Think': 'http://th1nk.info', 'math1as': 'http://www.math1as.com', 'rj1ng': 'http://rj1ng.com', 'Silver': 'https://www.iret.xyz', 'Sud0': 'http://sudalover.com', '几何_me7ell': 'http://blog.7ell.me', 'Ricky': 'https://rickyhao.com', 'Omego': 'http:/xd-a8.com', '1phan': 'http://1phan.cc', 'grt1st': 'http://www.grt1st.cn', 'Klaus': 'http://klaus.link', '天上的因幡': 'http://rabbithouse.me', 'skye': 'http://sky3.pw'}}}\n"
     ]
    }
   ],
   "source": [
    "friends={}\n",
    "result={}\n",
    "dict={}\n",
    "dict[init_url]=from_link_search_friend(init_url)\n",
    "friends['L-team']=dict\n",
    "print('now %s' %friends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_remove_dup(four_set):\n",
    "    next={}\n",
    "    for i in four_set.keys():\n",
    "        for j in four_set[i].keys():\n",
    "            for k in four_set[i][j].keys():\n",
    "                next[k]=four_set[i][j][k]\n",
    "\n",
    "    next={next[key]:key for key in next}\n",
    "    next={next[key]:key for key in next}\n",
    "    return next\n",
    "#next=set_remove_dup(friends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoset_compare_remove_dup(first_set,second_set):\n",
    "    netodel=[]\n",
    "    for i in first_set.keys():\n",
    "        for j in first_set[i].keys():\n",
    "            for k in second_set.keys():\n",
    "                if j==second_set[k]:\n",
    "                    netodel.append(second_set[k])\n",
    "    netodel=list(set(netodel))\n",
    "    second_set={second_set[key]:key for key in second_set}\n",
    "    for i in netodel:\n",
    "        second_set.pop(i)\n",
    "    second_set={second_set[key]:key for key in second_set}\n",
    "    return second_set\n",
    "#twoset_compare_remove_dup(result,next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_result(security_host):\n",
    "    for i in security_host.keys():\n",
    "        #print(friends[i][j][k])\n",
    "        dict={}\n",
    "        dict[security_host[i]]=''\n",
    "        result[i]=dict\n",
    "    return result\n",
    "#result=init_result(security_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_search(security_host):\n",
    "    print(\"[+]Start first search strategy\")\n",
    "    sur_link=security_host.copy()\n",
    "    friends={}\n",
    "    for key in security_host.keys():\n",
    "        #print('%s' %security_host[key])   \n",
    "        friend_link=from_index_search_links(security_host[key])\n",
    "        dict={}\n",
    "        if friend_link:\n",
    "            sur_link.pop(key)\n",
    "            #print('%s found ' %security_host[key])\n",
    "            dict[security_host[key]]=from_link_search_friend(friend_link)\n",
    "            friends[key]=dict\n",
    "\n",
    "        else:\n",
    "            #print('%s not found ' %security_host[key])\n",
    "            pass\n",
    "    return friends,sur_link\n",
    "#friends,sur_link=first_search(security_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_search(sur_link):\n",
    "    print(\"[+]Start second search strategy\")\n",
    "    needtodel=[]\n",
    "    for i in sur_link.keys():\n",
    "        friend_link,key=search_link(i,sur_link[i])\n",
    "        if not friend_link:\n",
    "            pass\n",
    "        else:\n",
    "            #print(friend_link,key)\n",
    "            dict={}\n",
    "            dict[sur_link[i]]=friend_link\n",
    "            friends[i]=dict\n",
    "            needtodel.append(key)\n",
    "    for i in needtodel:\n",
    "        sur_link.pop(i)\n",
    "    return friends,sur_link\n",
    "#friends,sur_link=second_search(sur_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(result,friends,sur_link):\n",
    "    for key in friends.keys():\n",
    "        result[key]=friends[key]\n",
    "    for i in sur_link.keys():\n",
    "        dict={}\n",
    "        dict[sur_link[i]]='nolink'\n",
    "        result[i]=dict\n",
    "    return result\n",
    "#result=get_result(result,friends,sur_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start search security blogs\n"
     ]
    }
   ],
   "source": [
    "#自身去重，与上次对比去重，得到下步需要探测的字典\n",
    "while(True):\n",
    "    next=set_remove_dup(friends)\n",
    "    next=twoset_compare_remove_dup(result,next)\n",
    "    security_host,no_security_host=find_security_blog(next)\n",
    "    result=init_result(security_host)\n",
    "    friends,sur_link=first_search(security_host)\n",
    "    friends,sur_link=second_search(sur_link)\n",
    "    result=get_result(result,friends,sur_link)\n",
    "    print(\"[+]Now result set length:{}\".format(len(result)))\n",
    "    print(\"[+]one epoch done!\")\n",
    "    with open('result.txt', 'w', encoding='gbk', errors='ignore') as file:\n",
    "        file.write(str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
